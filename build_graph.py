import pickle
import math
from operator import itemgetter
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import time
import numpy as np
import pandas as pd 
#from pandarallel import pandarallel
import pickle
from tqdm import tqdm 
import dgl


def userTopItems(dataset, K=10):
    '''
    功能是根据给定的数据集，计算每个用户的Top K推荐物品，并将结果保存到文件中。

    函数 userTopItems 的输入参数为 dataset（数据集名称）和可选参数 K（默认为10，表示每个用户的Top K推荐物品数量）。

    从文件中加载训练数据集 train.pkl，该文件包含用户的历史会话数据。
    创建字典 u_dict 来存储用户的历史会话数据和字典 item_pop 来存储物品的流行度。
    统计物品的流行度：遍历每个用户的历史会话数据，对于每个会话中的物品，将其流行度加一。
    根据物品的流行度计算用户对物品的喜好程度：遍历每个用户的历史会话数据，对于每个会话中的物品，根据物品的流行度计算用户对该物品的喜好程度，并将结果存储到字典 u_dict 中。
    创建字典 user_topK 来存储每个用户的Top K推荐物品。
    对于每个用户，根据其对物品的喜好程度，选取Top K热门物品和Top K冷门物品作为推荐物品，并将结果存储到字典 user_topK 中。
    将用户的Top K推荐物品保存到文件 userTopItems.pkl 中。
    请注意，代码中使用了 tqdm 来显示进度条，以便在处理大量数据时能够实时显示进度。另外，代码中有两处文件路径需要根据实际情况进行修改，分别是训练数据集文件路径和保存用户Top K物品的文件路径。
    Args:
        dataset:
        K:

    Returns:

    '''


    # 从文件中加载训练数据
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/train.pkl', 'rb') as f:
        session_data = pickle.load(f)

    # 创建字典来存储用户的历史会话数据和物品的流行度
    u_dict = dict()  # 存储用户的历史会话数据
    item_pop = dict()  # 存储物品的流行度

    # 统计物品的流行度
    for uid in tqdm(session_data):
        u_sess = session_data[uid]
        for sess in u_sess:
            for vid in sess:
                item_pop.setdefault(vid, 0)
                item_pop[vid] += 1

    # 根据物品的流行度计算用户对物品的喜好程度
    for uid in tqdm(session_data):
        u_sess = session_data[uid]
        u_dict.setdefault(uid, dict())
        for sess in u_sess:
            for vid in sess:
                u_dict[uid].setdefault(vid, 0)
                u_dict[uid][vid] += (item_pop[vid] * 0.75)

    user_topK = {}  # 存储每个用户的Top K物品

    # 根据用户对物品的喜好程度，选取Top K热门物品和Top K冷门物品作为用户的推荐物品
    for user in u_dict:
        hot_items = [key for key, value in sorted(u_dict[user].items(), key=itemgetter(1), reverse=True)[:K]]
        cold_items = [key for key, value in sorted(u_dict[user].items(), key=itemgetter(1), reverse=False)[:K]]
        user_topK[user] = list(set(hot_items).union(set(cold_items)))

    # 将用户的Top K物品保存到文件中
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/userTopItems.pkl', 'wb') as f:
        pickle.dump(user_topK, f)


def itemTopUsers(dataset, K=10):

    '''

    功能是根据给定的数据集，计算每个物品的Top K推荐用户，并将结果保存到文件中。

    函数 itemTopUsers 的输入参数为 dataset（数据集名称）和可选参数 K（默认为10，表示每个物品的Top K推荐用户数量）。

    从文件中加载训练数据集 train.pkl，该文件包含物品的历史会话数据。
    创建字典 v_dict 来存储物品的历史会话数据和字典 user_active 来存储用户的活跃度。
    统计用户的活跃度：遍历每个用户的历史会话数据，计算每个用户的活跃度（会话数量的总和），并将结果存储到字典 user_active 中。
    根据用户的活跃度计算物品的受欢迎程度：遍历每个用户的历史会话数据，对于每个会话中的物品，根据用户的活跃度计算物品的受欢迎程度，并将结果存储到字典 v_dict 中。
    创建字典 item_topK 来存储每个物品的Top K推荐用户。
    对于每个物品，根据其受欢迎程度，选取Top K活跃用户和Top K不活跃用户作为推荐用户，并将结果存储到字典 item_topK 中。
    将物品的Top K推荐用户保存到文件 itemTopUtems.pkl 中。
    请注意，代码中使用了 tqdm 来显示进度条，以便在处理大量数据时能够实时显示进度。另外，代码中有两处文件路径需要根据实际情况进行修改，分别是训练数据集文件路径和保存物品Top K用户的文件路径。
    Args:
        dataset:
        K:

    Returns:

    '''
    # 从文件中加载训练数据
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/train.pkl', 'rb') as f:
        session_data = pickle.load(f)

    # 创建字典来存储物品的历史会话数据和用户的活跃度
    v_dict = dict()  # 存储物品的历史会话数据
    user_active = dict()  # 存储用户的活跃度

    # 统计用户的活跃度
    for uid in tqdm(session_data):
        u_sess = session_data[uid]
        user_active[uid] = sum([len(sess) for sess in u_sess])

    # 根据用户的活跃度计算物品的受欢迎程度
    for uid in tqdm(session_data):
        u_sess = session_data[uid]

        for sess in u_sess:
            for vid in sess:
                v_dict.setdefault(vid, dict())
                v_dict[vid].setdefault(uid, 0)
                v_dict[vid][uid] += (user_active[uid] * 0.75)

    item_topK = {}  # 存储每个物品的Top K用户

    # 根据物品的受欢迎程度，选取Top K活跃用户和Top K不活跃用户作为物品的推荐用户
    for item in v_dict:
        hot_users = [key for key, value in sorted(v_dict[item].items(), key=itemgetter(1), reverse=True)[:K]]
        cold_users = [key for key, value in sorted(v_dict[item].items(), key=itemgetter(1), reverse=False)[:K]]
        item_topK[item] = list(set(hot_users).union(set(cold_users)))

    # 将物品的Top K用户保存到文件中
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/itemTopUtems.pkl', 'wb') as f:
        pickle.dump(item_topK, f)


def userCF(dataset):
    """
    计算用户之间的相似度
        功能是计算用户之间的相似度，并将每个用户的Top K相似用户保存到文件中。

        函数 userCF 的输入参数为 dataset（数据集名称）。

        创建字典 vid_user，用于存储物品和对应的用户集合。
        创建字典 user_sim_matrix，用于存储用户之间的相似度矩阵。
        创建字典 uid_vcount，用于存储用户和其观看过的物品数量。
        从文件中加载训练数据集 train.pkl。
        构建物品和对应的用户集合的字典 vid_user，以及用户和其观看过的物品数量的字典 uid_vcount。
        计算用户之间的相似度：遍历物品和对应的用户集合，对于每对不同的用户，增加其相似度值。
        根据观看过的物品数量归一化相似度，得到最终的用户相似度矩阵。
        创建字典 user_topK，用于存储每个用户的Top K相似用户。
        选取每个用户的Top K相似用户，并将结果存储到字典 user_topK 中。
        将用户的Top K相似用户保存到文件 u2u_sim.pkl 中。
        请注意，代码中使用了 tqdm 来显示进度条，以便在处理大量数据时能够实时显示进度。另外，代码中有一处文件路径需要根据实际情况进行修改，即保存用户相似度矩阵的文件路径。
    """
    vid_user = {}  # 存储物品和对应的用户集合
    user_sim_matrix = {}  # 存储用户之间的相似度矩阵
    uid_vcount = {}  # 存储用户和其观看过的物品数量
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/train.pkl', 'rb') as f:
        session_data = pickle.load(f)  # 加载训练数据集

    # 构建物品和对应的用户集合的字典，以及用户和其观看过的物品数量的字典
    for uid in tqdm(session_data):
        u_sess = session_data[uid]
        uid_vcount.setdefault(uid, set())

        for sess in u_sess:
            for vid in sess:
                if vid not in vid_user:
                    vid_user[vid] = set()
                vid_user[vid].add(uid)
                uid_vcount[uid].add(vid)

    # 计算用户之间的相似度
    for vid, users in tqdm(vid_user.items()):
        for u in users:
            for v in users:
                if u == v:
                    continue

                user_sim_matrix.setdefault(u, {})
                user_sim_matrix[u].setdefault(v, 0)
                user_sim_matrix[u][v] += (1 / len(users))

    # 根据观看过的物品数量归一化相似度得到最终的用户相似度矩阵
    for u, related_users in user_sim_matrix.items():
        for v, count in related_users.items():
            user_sim_matrix[u][v] = count / math.sqrt(len(uid_vcount[u]) * len(uid_vcount[v]))

    user_topK = {}  # 存储每个用户的Top K相似用户

    # 选取每个用户的Top K相似用户
    for user in user_sim_matrix:
        user_topK[user] = sorted(user_sim_matrix[user].items(), key=itemgetter(1), reverse=True)[:100]
    # 假数据
    user_topK = {1: [(2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 2: [(1, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 3: [(1, 0.05555555555555555), (2, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 4: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 5: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 6: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 7: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 8: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 9: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 10: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 11: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 12: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 13: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 14: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 15: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 16: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (17, 0.05555555555555555), (18, 0.05555555555555555)], 17: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (18, 0.05555555555555555)], 18: [(1, 0.05555555555555555), (2, 0.05555555555555555), (3, 0.05555555555555555), (4, 0.05555555555555555), (5, 0.05555555555555555), (6, 0.05555555555555555), (7, 0.05555555555555555), (8, 0.05555555555555555), (9, 0.05555555555555555), (10, 0.05555555555555555), (11, 0.05555555555555555), (12, 0.05555555555555555), (13, 0.05555555555555555), (14, 0.05555555555555555), (15, 0.05555555555555555), (16, 0.05555555555555555), (17, 0.05555555555555555)], 19: [(20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 20: [(19, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 21: [(19, 0.043478260869565216), (20, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 22: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 23: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 24: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 25: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 26: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 27: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 28: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 29: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 30: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 31: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 32: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 33: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 34: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 35: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 36: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 37: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 38: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 39: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (40, 0.043478260869565216), (41, 0.043478260869565216)], 40: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (41, 0.043478260869565216)], 41: [(19, 0.043478260869565216), (20, 0.043478260869565216), (21, 0.043478260869565216), (22, 0.043478260869565216), (23, 0.043478260869565216), (24, 0.043478260869565216), (25, 0.043478260869565216), (26, 0.043478260869565216), (27, 0.043478260869565216), (28, 0.043478260869565216), (29, 0.043478260869565216), (30, 0.043478260869565216), (31, 0.043478260869565216), (32, 0.043478260869565216), (33, 0.043478260869565216), (34, 0.043478260869565216), (35, 0.043478260869565216), (36, 0.043478260869565216), (37, 0.043478260869565216), (38, 0.043478260869565216), (39, 0.043478260869565216), (40, 0.043478260869565216)]}

    # 将用户的Top K相似用户保存到文件中
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/u2u_sim.pkl', 'wb') as f:
        pickle.dump(user_topK, f)


def itemCF(dataset):
    """
    计算物品之间的相似度
    `itemCF` 函数用于计算物品之间的相似度，并将每个物品的Top K相似物品保存到文件中。

    变量和方法功能的注释如下：

    - `uid_item`：字典，存储每个用户和其观看的物品集合。
    - `item_sim_matrix`：字典，存储物品之间的相似度矩阵。
    - `vid_ucount`：字典，存储每个物品对应的用户数量。

    加载训练数据集：
    - 从文件中加载训练数据集 `train.pkl`。

    构建用户和物品的字典：
    - 遍历每个用户的观看历史，在 `uid_item` 字典中存储每个用户和其观看的物品集合。
    - 在 `vid_ucount` 字典中存储每个物品对应的用户数量。

    计算物品之间的相似度：
    - 遍历每个用户的观看历史，对于每对不同的物品，增加其相似度值。

    归一化相似度得到最终的物品相似度矩阵：
    - 遍历物品相似度矩阵 `item_sim_matrix`，计算每对物品之间的相似度，并进行归一化。

    选取每个物品的Top K相似物品：
    - 遍历物品相似度矩阵 `item_sim_matrix`，对于每个物品，选取相似度最高的前 K 个物品。

    保存结果到文件：
    - 将每个物品的Top K相似物品保存到文件 `i2i_sim
    """
    uid_item = {}  # 存储用户和其观看的物品集合   原始 {1:[[a,b],[c]]}  变成 {1:{a,b,c}}
    item_sim_matrix = {}  # 存储物品之间的相似度矩阵
    vid_ucount = {}  # 存储物品和对应的用户数量  比如 {1:{a,b,c}，2:{d,e}}  --> {{1},{1},{1},{2},{2}}
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/train.pkl', 'rb') as f:
        session_data = pickle.load(f)  # 加载训练数据集

    # 构建用户和其观看的物品集合的字典，以及物品和对应的用户数量的字典
    for uid in tqdm(session_data):
        u_sess = session_data[uid]
        uid_item[uid] = set()

        for sess in u_sess:
            for vid in sess:
                uid_item[uid].add(vid)
                vid_ucount.setdefault(vid, set())
                vid_ucount[vid].add(uid)

    # 计算物品之间的相似度
    for uid, items in tqdm(uid_item.items()): # {1:{a,b,c}}从这里取
        for v in items:
            for _v in items:
                if _v == v:# 跳过自己本身
                    continue

                item_sim_matrix.setdefault(v, {})
                item_sim_matrix[v].setdefault(_v, 0)
                item_sim_matrix[v][_v] += (1 / len(items))  # 值的计算： 1/项目总个数  比如出现一个2  则2对应的相似度是 1/项目总数，若后面还有一个2，则相似度为 1/项目总数+ 1/项目总数

    # 根据用户数量归一化相似度得到最终的物品相似度矩阵
    for v, related_items in item_sim_matrix.items():
        for _v, count in related_items.items():
            item_sim_matrix[v][_v] = count / math.sqrt(len(vid_ucount[v]) * len(vid_ucount[_v]))

    item_topK = {}  # 存储每个物品的Top K相似物品
    print(item_sim_matrix)
    # 选取每个物品的Top K相似物品
    for item in item_sim_matrix:
        item_topK[item] = sorted(item_sim_matrix[item].items(), key=itemgetter(1), reverse=True)[:200]
    print(item_topK)
    # 将物品的Top K相似物品保存到文件中
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset}/i2i_sim.pkl', 'wb') as f:
        pickle.dump(item_topK, f)


def uui_graph(dataset_name, sample_size, topK, add_u=True, add_v=True):
    """
    根据给定的数据集名称、样本大小和topK值构建图结构。

    参数:
        dataset_name (str): 数据集名称
        sample_size (int): 样本大小
        topK (int): topK值
        add_u (bool): 是否添加用户节点，默认为True
        add_v (bool): 是否添加物品节点，默认为True

    返回:
        G (DGLGraph): 构建的图结构
        item_num (int): 物品节点数量

    功能是根据给定的数据集名称、样本大小和topK值构建图结构。具体的操作如下：

    导入所需的库。
    定义变量pre、nxt、src_v和dst_u，它们分别表示前驱节点、后继节点、物品节点和用户节点的列表。
    调用itemCF函数构建物品之间的相似性关系。
    调用userCF函数构建用户之间的相似性关系。
    使用pickle库从文件中加载图数据和邻接矩阵数据。
    对图进行采样，将采样后的节点和边添加到pre、nxt、src_v和dst_u列表中。
    使用pickle库从文件中加载用户之间的相似性信息和物品之间的相似性信息。
    根据物品相似性信息生成物品节点之间的关系，将结果保存到topv_src和topv_dst列表中。
    根据用户相似性信息生成用户节点之间的关系，将结果保存到u_src和u_dst列表中。
    计算邻接矩阵的平均密度并输出。
    计算物品节点的数量。
    根据需要是否添加用户节点和物品节点的边关系。
    创建空的DGL图。
    将之前收集的节点和边添加到DGL图中。
    添加自环边。
    返回构建的图结构和物品节点的数量。
    """


    src_v = []  # 物品节点列表
    dst_u = []  # 用户节点列表

    # 构建物品之间的相似性关系   从train二维表筛选  将物品的Top K相似物品保存到 i2i_sim.pkl
    itemCF(dataset_name)   # 协同过滤变体

    '''
    实际上是基于物品协同过滤（Item-based Collaborative Filtering）的推荐算法，也被称为基于用户行为的协同过滤算法。

    在物品协同过滤算法中，相似度是通过计算物品之间的相似度来确定的，然后利用这些相似度来为用户进行推荐。在这个算法中，我们首先构建物品和对应的用户集合的字典，然后计算用户之间的相似度。这些步骤与物品协同过滤算法相同。
    
    然而，这个算法中也涉及了一些用户的计算和归一化的步骤，以确保相似度得分在可控范围内。这些步骤使得算法更加灵活和个性化，可以根据用户观看的物品数量调整相似度得分，以提供更准确的推荐结果。
    
    因此，可以说这个算法是物品协同过滤算法的一种变体，加入了一些用户行为的计算和调整步骤。这样的变体可以根据具体的需求和数据集特点进行调整，以获得更好的推荐效果。
    '''
    # 构建用户之间的相似性关系
    userCF(dataset_name)           # u2u_sim

    # 从pickle文件中加载图数据
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/train.pkl', 'rb') as f:
        graph = pickle.load(f)

    # 从pickle文件中加载邻接矩阵数据
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/adj_{sample_size}.pkl', 'rb') as f:
        adj = pickle.load(f)
    adj_in = adj[0]
    adj_out = adj[1]
    print('adj_in:', len(adj_in))
    print('adj_out:', len(adj_out))

    pre = []  # 输入前驱节点列表

    '''
            
            adj_in = {
                'item1': ['item2', 'item3'],
                'item2': ['item1'],
                'item3': ['item1'],
                'item4': ['item1'],
                'item5': ['item2'],
                'item6': ['item3']
            }
            
            pre: [1, 1, 2, 1, 3, 1]
            nxt: [2, 3, 1, 1, 1, 1]
            
            
            dst_u: [item2, item3, item1, item1, item1, item2]
            src_v: [item1, item1, item2, item3, item4, item5]




    
    
    
    
        对输入邻接矩阵 adj_in 进行遍历，构建用户-物品之间的连接关系
        对于节点 1，其相邻节点为 2 和 3，将连接关系添加到 pre 和 nxt 列表中：

        pre：[1, 1]
        nxt：[2, 3]
        对于节点 2，其相邻节点为 1，将连接关系添加到 pre 和 nxt 列表中：
        
        pre：[1, 1, 2]
        nxt：[2, 3, 1]
        对于节点 3，其相邻节点为 1，将连接关系添加到 pre 和 nxt 列表中：
        
        pre：[1, 1, 2, 1]
        nxt：[2, 3, 1, 1]
    '''
    nxt = []  # 输入后继节点列表

    ## 对图进行采样
    for i in range(len(adj_in)):
        if i == 0:
            continue
        _pre = []
        _nxt = []
        for item in adj_in[i]:
            _pre.append(i)
            _nxt.append(item)
        pre += _pre
        nxt += _nxt

    o_pre = [] # 输入前驱节点列表


    '''
        对输出邻接矩阵 adj_out 进行遍历，构建物品-用户之间的连接关系。
        对于节点 1，其相邻节点为 2 和 3，将连接关系添加到 o_pre 和 o_nxt 列表中：
        
        o_pre：[1, 1]
        o_nxt：[2, 3]
        对于节点 2，其相邻节点为 1，将连接关系添加到 o_pre 和 o_nxt 列表中：
        
        o_pre：[1, 1, 2]
        o_nxt：[2, 3, 1]
        对于节点 3，其相邻节点为 1，将连接关系添加到 o_pre 和 o_nxt 列表中：
        
        o_pre：[1, 1, 2, 1]
        o_nxt：[2, 3, 1, 1]
    
    '''
    o_nxt = [] # 输入后继节点列表   注意：：是边的前驱和后继
    for i in range(len(adj_out)):
        if i == 0:
            continue
        _pre = []
        _nxt = []
        for item in adj_out[i]:
            _pre.append(i)
            _nxt.append(item)
        o_pre += _pre
        o_nxt += _nxt

    # 构建用户-物品之间的关系

    '''
        遍历图数据中的每个用户和物品序列，构建用户-物品之间的连接关系。
        对于用户 user1 和物品序列 [item1, item2, item3]：
        
        将物品序列的前一个物品添加到 pre 列表中：[1, 1, 2, 1, item1, item2]
        将物品序列的后一个物品添加到 nxt 列表中：[2, 3, 1, 1, item2, item3]
        将当前用户重复添加到 dst_u 列表中：[user1, user1, user1, user1, user1, user1]
        将物品序列中的每个物品添加到 src_v 列表中：[item1, item2, item3]
        对于用户 user2 和物品序列 `[itemApologies for the incomplete response. Here's the continuation of the example:
        
        对于用户 user2 和物品序列 [item2, item5]：
        
        将物品序列的前一个物品添加到 pre 列表中：[1, 1, 2, 1, item1, item2, item2]
        将物品序列的后一个物品添加到 nxt 列表中：[2, 3, 1, 1, item2, item3, item5]
        将当前用户重复添加到 dst_u 列表中：[user1, user1, user1, user1, user1, user1, user2]
        将物品序列中的每个物品添加到 src_v 列表中：[item1, item2, item3, item2, item5]
        对于用户 user3 和物品序列 [item1, item3, item4, item6]：
        
        将物品序列的前一个物品添加到 pre 列表中：[1, 1, 2, 1, item1, item2, item2, item1, item3, item4]
        将物品序列的后一个物品添加到 nxt 列表中：[2, 3, 1, 1, item2, item3, item5, item3, item4, item6]
        将当前用户重复添加到 dst_u 列表中：[user1, user1, user1, user1, user1, user1, user2, user3, user3, user3]
        将物品序列中的每个物品添加到 src_v 列表中：[item1, item2, item3, item2, item5, item1, item3, item4, item6]
    
    '''
    for u in tqdm(graph, desc='build the graph...', leave=False):
        u_seqs = graph[u]
        for s in u_seqs:
            pre += s[:-1]
            nxt += s[1:]
            dst_u += [u for _ in s]
            src_v += s

    # 从pickle文件中加载用户相似性信息
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/u2u_sim.pkl', 'rb') as f:
        u2u_sim = pickle.load(f)

    # 从pickle文件中加载物品相似性信息
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/i2i_sim.pkl', 'rb') as f:
        i2i_sim = pickle.load(f)

    print(u2u_sim)
    print(i2i_sim)

    topv_src = [] # 用于存储物品相似性信息中的顶部K个相似物品的源物品
    topv_dst = [] # 用于存储物品相似性信息中的顶部K个相似物品的目标物品
    count_v = 0

    print("u2u_sim+i2i_sim")
    print(u2u_sim)
    print(i2i_sim)
    for v in tqdm(i2i_sim, desc='gen_seq...', leave=False):


        print("v:")
        print(v)
        tmp_src = [] # 临时存储满足条件的相似物品的源物品
        tmp_dst = [] # 临时存储满足条件的相似物品的目标物品

        exclusion = adj_in[v] + adj_out[v] #排除列表exclusion，包含了物品v的入边和出边。这个列表用于排除已经与物品v相连的物品，避免重复连接。
        print(exclusion)
        for (vid, value) in i2i_sim[v][:topK][:int(len(exclusion))]:  # 在相似物品列表i2i_sim[v]的前K个条目中遍历，对于每个相似物品(vid, value)，执行以下操作：
            if vid not in exclusion:    # 如果相似物品vid不在排除列表exclusion中，则将其添加到tmp_src和tmp_dst中。
                tmp_src.append(vid)    # 将tmp_src和tmp_dst中的元素添加到topv_src和topv_dst中
                tmp_dst.append(v)

            print(tmp_src)
            print(tmp_dst)
        topv_src += tmp_src
        topv_dst += tmp_dst

        print(topv_dst)
        print(topv_dst)

    u_src = []  # 创建一个空列表 u_src 用于存储用户源节点
    u_dst = []  # 创建一个空列表 u_dst 用于存储用户目标节点

    # 使用 tqdm 迭代 u2u_sim 字典的内容，desc 是 tqdm 进度条的描述
    for u in tqdm(u2u_sim, desc='gen_seq...', leave=False):
        tmp_src = []  # 创建一个临时空列表 tmp_src 用于存储用户源节点
        tmp_dst = []  # 创建一个临时空列表 tmp_dst 用于存储用户目标节点
        for (uid, value) in u2u_sim[u][:topK]:  # 迭代用户 u 相似性字典的前 topK 个相似用户
            tmp_src.append(uid)  # 将相似用户的 ID 添加到 tmp_src
            tmp_dst.append(u)  # 将用户 u 的 ID 添加到 tmp_dst
        u_src += tmp_src  # 将 tmp_src 列表中的内容追加到 u_src 列表中
        u_dst += tmp_dst  # 将 tmp_dst 列表中的内容追加到 u_dst 列表中

    count = 0  # 创建一个计数器变量 count，初始化为 0
    for i in adj_in:  # 迭代列表 adj_in
        count += len(i)  # 计算每个元素（列表） i 的长度并加到 count 上
    print('local ajdency-in:', count / len(adj_in))  # 打印 "local ajdency-in" 和平均邻接边数

    count = 0  # 重置计数器 count 为 0
    for i in adj_out:  # 迭代列表 adj_out
        count += len(i)  # 计算每个元素（列表） i 的长度并加到 count 上
    print('local ajdency-out:', count / len(adj_out))  # 打印 "local ajdency-out" 和平均邻接边数

    item_num = max(max(pre), max(nxt)) + 1  # 计算前驱（pre）和后继（nxt）中的最大值，并加 1，存储在 item_num 中
    print('addiotn item num', item_num)  # 打印 "addiotn item num" 和 item_num 值

    user_num = max(max(u_src), max(u_dst))  # 计算 u_src 和 u_dst 列表中的最大值
    u_src = [u + item_num for u in u_src]  # 将 u_src 列表中的每个元素加上 item_num
    u_dst = [u + item_num for u in u_dst]  # 将 u_dst 列表中的每个元素加上 item_num
    dst_u = [u + item_num for u in dst_u]  # 将 dst_u 列表中的每个元素加上 item_num


    # in表示从值指向键 'item1': ['item2'],   2-->1
    # 创建空的DGL图
    G = dgl.graph((pre, nxt))
    G = dgl.add_edges(G, nxt, pre)
    G = dgl.add_edges(G, dst_u, src_v)
    G = dgl.add_edges(G, src_v, dst_u)
    print(G)
    if add_u:
        G = dgl.add_edges(G, u_src, u_dst)
        G = dgl.add_edges(G, u_dst, u_src)

    if add_v:
        G = dgl.add_edges(G, topv_src, topv_dst)
        G = dgl.add_edges(G, topv_dst, topv_src)

    G = dgl.add_self_loop(G)

    return G, item_num


def sample_relations(dataset_name, num, sample_size=20):
    """
    根据给定的数据集名称、数量和采样大小构建关系数据。

    参数:
        dataset_name (str): 数据集名称
        num (int): 数据集中的节点数量
        sample_size (int): 采样大小，默认为20

    返回:
        None


        功能是根据给定的数据集名称、数量和采样大小构建关系数据。具体的操作如下：

        创建空的邻接矩阵和关系列表。
        使用pickle库从文件中加载图数据。
        构建关系数据，遍历图数据中的用户序列，提取相邻节点之间的关系，并添加到关系列表中。
        构建邻接矩阵，遍历关系列表，统计每个节点的出边和入边，并保存到邻接矩阵中。
        对邻接矩阵进行排序，获取每个节点的前sample_size个出边和入边。
        对邻接矩阵进行采样，保留每个节点的前sample_size个出边和入边。
        将采样后的邻接矩阵保存到pickle文件。
    """

    # 创建空的邻接矩阵和关系列表
    adj1 = [dict() for _ in range(num)] # 存储出边

    '''
        例：
            adj1 = {
                1: {2: 3, 3: 2},
                2: {1: 1, 3: 1},
                3: {1: 2, 2: 1}
            }
            
            adj2 = {
                1: {2: 1, 3: 2},
                2: {1: 3},
                3: {1: 1, 2: 1}
            }
            
            那么这个邻接矩阵表示的图有三个节点，节点之间的边的出现次数如下：

                节点 1 的出边：到节点 2 的边出现 3 次，到节点 3 的边出现 2 次。
                节点 2 的出边：到节点 1 的边出现 1 次，到节点 3 的边出现 1 次。
                节点 3 的出边：到节点 1 的边出现 2 次，到节点 2 的边出现 1 次。
            同时，节点之间的边的入现次数如下：
            
                节点 1 的入边：来自节点 2 的边出现 1 次，来自节点 3 的边出现 2 次。
                节点 2 的入边：来自节点 1 的边出现 3 次。
                节点 3 的入边：来自节点 1 的边出现 1 次，来自节点 2 的边出现 1 次。
            
    '''
    adj2 = [dict() for _ in range(num)] # 存储入边
    adj_in = [[] for _ in range(num)]
    adj_out = [[] for _ in range(num)]
    relation_out = []
    relation_in = []

    # 从pickle文件中加载图数据
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/train.pkl', 'rb') as f:
        graph = pickle.load(f)

    print(graph)

    # 构建关系数据
    for u in tqdm(graph, desc='build the graph...', leave=False):
        u_seqs = graph[u]
        for s in u_seqs:
            for i in range(len(s) - 1):
                relation_out.append([s[i], s[i + 1]])
                relation_in.append([s[i + 1], s[i]])

    # 构建邻接矩阵
    for tup in relation_out:
        if tup[1] in adj1[tup[0]].keys():
            adj1[tup[0]][tup[1]] += 1
        else:
            adj1[tup[0]][tup[1]] = 1
    for tup in relation_in:
        if tup[1] in adj2[tup[0]].keys():
            adj2[tup[0]][tup[1]] += 1
        else:
            adj2[tup[0]][tup[1]] = 1

    # 对邻接矩阵进行排序，获取前sample_size个边
    for t in range(1, num):
        x = [v for v in sorted(adj1[t].items(), reverse=True, key=lambda x: x[1])]
        adj_out[t] = [v[0] for v in x]

    for t in range(1, num):
        x = [v for v in sorted(adj2[t].items(), reverse=True, key=lambda x: x[1])]
        adj_in[t] = [v[0] for v in x]

    # 对邻接矩阵进行采样，保留前sample_size个边
    for i in range(1, num):
        adj_in[i] = adj_in[i][:sample_size]
    for i in range(1, num):
        adj_out[i] = adj_out[i][:sample_size]

    # 将采样后的邻接矩阵“adj_***文件”保存到pickle文件
    with open(f'E:/MyCode/PycharmCode/HG-GNN/data_processor/dataset/{dataset_name}/adj_{sample_size}.pkl', 'wb') as f:
        pickle.dump([adj_in, adj_out], f)